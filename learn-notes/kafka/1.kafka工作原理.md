
# kafka工作原理


## kafka如何保证百万级的写入速度
1. 页缓存技术 + 磁盘顺序写
2. 零拷贝技术

## kafka如何保证高效消费
零拷贝技术


## kafka 如何做到不丢失不重复消费
> 消息传递语义：
```
最多一次（at most once）: 消息可能丢失也可能被处理，但最多只会被处理一次。
可能丢失 不会重复


至少一次（at least once）: 消息不会丢失，但可能被处理多次。
可能重复 不会丢失


精确传递一次（exactly once）: 消息被处理且只会被处理一次。
不丢失 不重复 就一次

```
消息生产端： acks
0: producer完全不管broker的处理结果 回调也就没有用了 并不能保证消息成功发送 但是这种吞吐量最高
-1或者all: leader broker会等消息写入 并且ISR都写入后 才会响应，这种只要ISR有副本存活就肯定不会丢失，但吞吐量最低。
1: 默认的值 leader broker自己写入后就响应，不会等待ISR其他的副本写入，只要leader broker存活就不会丢失，即保证了不丢失，也保证了吞吐量。
所以设置为0时，实现了at most once，而且从这边看只要保证集群稳定的情况下，不设置为0，消息不会丢失。

但是还有一种情况就是消息成功写入，而这个时候由于网络问题producer没有收到写入成功的响应，producer就会开启重试的操作，直到网络恢复，消息就发送了多次。这就是at least once了。
kafka producer 的参数acks 的默认值为1，所以默认的producer级别是at least once。并不能exactly once。

Consumer端消息传递: consumer是靠offset保证消息传递的。

enable.auto.commit
若设置为true consumer在消费之前提交位移 就实现了at most once
若是消费后提交 就实现了 at least once 默认的配置就是这个。

kafka consumer的参数enable.auto.commit的默认值为true ，所以默认的consumer级别是at least once。也并不能exactly once。


精确一次




## 参考文章
https://www.cnblogs.com/sujing/p/10960832.html
https://www.cnblogs.com/gxyandwmm/p/11432598.html
